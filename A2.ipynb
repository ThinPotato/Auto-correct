{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1615908962928,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "keicKV6X8Y0Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zk2tzdcynYn"
   },
   "source": [
    "# **Read Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lpfFShdy3e5J"
   },
   "outputs": [],
   "source": [
    "# Read user data\n",
    "lastWord = \"\"\n",
    "words = defaultdict(dict)\n",
    "with open('Data/data.txt', 'r') as input:\n",
    "    for line in input:\n",
    "        touchpoints = [0,0, '']\n",
    "        line.strip\n",
    "        if line.startswith(\"===\"):\n",
    "            words[str(line)[3:len(str(line))-4]] = []\n",
    "            lastWord = str(line)[3:len(str(line))-4]\n",
    "        else:\n",
    "            tempPoints = str(line)[0:len(str(line))-2].split(\" \")\n",
    "            touchpoints[0] = float(tempPoints[1])\n",
    "            touchpoints[1] = float(tempPoints[2])\n",
    "            touchpoints[2] = tempPoints[0]\n",
    "            words[lastWord].append(touchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1615913307462,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "34cXvsWno6Yv",
    "outputId": "96c3f6f7-2867-4996-bd8e-0190d649e806"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>x_mm</th>\n      <th>y_mm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>4.025010</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>18.900047</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>12.950032</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d</td>\n      <td>9.975025</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>8.487521</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f</td>\n      <td>12.950032</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>g</td>\n      <td>15.925039</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>h</td>\n      <td>18.900047</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>i</td>\n      <td>23.362558</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>j</td>\n      <td>21.875053</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>k</td>\n      <td>24.850061</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>l</td>\n      <td>27.825070</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>m</td>\n      <td>24.850061</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>n</td>\n      <td>21.875053</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>o</td>\n      <td>26.337564</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>p</td>\n      <td>29.312572</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>q</td>\n      <td>2.537506</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r</td>\n      <td>11.462528</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>s</td>\n      <td>7.000017</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>t</td>\n      <td>14.437536</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>u</td>\n      <td>20.387550</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>v</td>\n      <td>15.925039</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>w</td>\n      <td>5.512514</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>x</td>\n      <td>9.975025</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>y</td>\n      <td>17.412542</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>z</td>\n      <td>7.000017</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td></td>\n      <td>12.950032</td>\n      <td>17.675043</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   key       x_mm       y_mm\n0    a   4.025010   9.625024\n1    b  18.900047  13.650034\n2    c  12.950032  13.650034\n3    d   9.975025   9.625024\n4    e   8.487521   5.600014\n5    f  12.950032   9.625024\n6    g  15.925039   9.625024\n7    h  18.900047   9.625024\n8    i  23.362558   5.600014\n9    j  21.875053   9.625024\n10   k  24.850061   9.625024\n11   l  27.825070   9.625024\n12   m  24.850061  13.650034\n13   n  21.875053  13.650034\n14   o  26.337564   5.600014\n15   p  29.312572   5.600014\n16   q   2.537506   5.600014\n17   r  11.462528   5.600014\n18   s   7.000017   9.625024\n19   t  14.437536   5.600014\n20   u  20.387550   5.600014\n21   v  15.925039  13.650034\n22   w   5.512514   5.600014\n23   x   9.975025  13.650034\n24   y  17.412542   5.600014\n25   z   7.000017  13.650034\n26      12.950032  17.675043"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dictionary\n",
    "with open('Data/unigram.dict', 'rb') as unigramModelFile:\n",
    "    unigramModel = pickle.load(unigramModelFile)\n",
    "unigramModelFile.close()\n",
    "\n",
    "# Read keyboard data\n",
    "keyboard_raw = pd.read_csv(\"Data/keyboard.csv\")\n",
    "keyboard = keyboard_raw[['key', 'x_mm', 'y_mm']]\n",
    "keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuntaNwhyuJj"
   },
   "source": [
    "# **Unigram Language Model Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1615909214779,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "AaTGhNueN9hD"
   },
   "outputs": [],
   "source": [
    "# Keyboard size and dual Gaussian model parameters\n",
    "key_width = 3\n",
    "key_height = 4\n",
    "a = 2.403\n",
    "b = 0.017\n",
    "c = 2.295\n",
    "d = 0.016\n",
    "\n",
    "def get_likelihood(p, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the likelihood that a touch point p is from the 2D Gaussian distribution N(mu, sigma)\n",
    "    \"\"\"  \n",
    "    lik = a * math.exp(-(math.pow((p[0]-mu[0]),2)/(2*(a+b*math.pow(key_width,2)))+(math.pow(p[1]-mu[1],2)/(2*(c+d*math.pow(key_height,2))))))\n",
    "    return lik          \n",
    "\n",
    "def is_letter(p, letter):\n",
    "    \"\"\"\n",
    "    Determine if touch point p is located inside the boundary of the key: letter\n",
    "    \"\"\"\n",
    "    tmp = keyboard.loc[keyboard['key'] == letter]\n",
    "    x_mm = tmp.iloc[0]['x_mm']\n",
    "    y_mm = tmp.iloc[0]['y_mm']\n",
    "    if p[0] < (x_mm + key_width) and p[0] > x_mm and p[1] < (y_mm + key_height) and p[1] > y_mm:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def get_literal_string(touchpoints):\n",
    "    \"\"\" \n",
    "    Compute the literal string using is_letter(p, letter) method for a collection of touch points that represents a word. \n",
    "          If a touch point does not fall inside any key boundary, use '?' to represent the corresponding character.\n",
    "    \"\"\"\n",
    "    literal_string = \"\"\n",
    "    tmp = keyboard['key']\n",
    "    for touchpoint in touchpoints:\n",
    "        found = False\n",
    "        for i in range(25):\n",
    "            letter = tmp.values[i]\n",
    "            if is_letter(touchpoint, letter):\n",
    "                literal_string += letter\n",
    "                found = True\n",
    "        if found == False:\n",
    "            literal_string+= \"?\"\n",
    "    return literal_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1615909358093,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "_op29UXGRmc0"
   },
   "outputs": [],
   "source": [
    "def unigram_lm_decoder(touchpoints):\n",
    "    \"\"\"\n",
    "    A language decoder that uses the dual Gaussian touch point spatial disrtibution model and a unigram language model.\n",
    "    Input: a list/collection of touch points that represents a certain word\n",
    "    Output: the decoded word for the input\n",
    "    \n",
    "    Step a --- Get all possible words and their corresponding probabilities from the dictionary. \n",
    "          Use the length of the correct word to filter possible words\n",
    "          You may also use the first and/or the last touchpoint to further narrow down possible words\n",
    "    \"\"\"\n",
    "    possible_words = []\n",
    "    length = len(touchpoints)\n",
    "    firstTP = touchpoints[0]\n",
    "    lastTP = touchpoints[len(touchpoints)-1]\n",
    "    possible_words = dict(filter(lambda x: len(str(x[0])) == length, unigramModel.items()))\n",
    "    #possible_words = dict(filter(lambda x: is_letter(firstTP, x[0][:1]), unigramModel.items()))\n",
    "    \n",
    "    # Calculate p(w|s_1, s_2, ... s_n) ~ p(s_1, s_2, ..., s_n|w)*p(w) = \\Pi(p(s_i|c_i))p(w) for each possible word\n",
    "    p_w_s = []                  # Holds p(w|s_1, s_2, ..., s_n) for all possible words\n",
    "    for item in possible_words:\n",
    "        word = item                  # The current possible word\n",
    "        p_w =  possible_words[item]  # Probability of the current possible word in the unigram language model\n",
    "        p_s_w = 1                 # Holds p(s_1, s_2, ..., s_n|w) for the current possible word\n",
    "\n",
    "        for j, letter in enumerate(list(word)):\n",
    "            currentPoints = touchpoints[j]\n",
    "            # Step b --- Apply the spatial model to get p(s_i|c_i)\n",
    "            tmp = keyboard.loc[keyboard['key'] == letter]\n",
    "            x_mm = tmp.iloc[0]['x_mm']\n",
    "            y_mm = tmp.iloc[0]['y_mm']\n",
    "            mu = [x_mm + (0.5*key_width), y_mm + (0.5*key_height)] # mu = center of key ci\n",
    "\n",
    "            sigma =[a+b*math.pow(key_width,2),c+d*math.pow(key_height,2)] # [sigma_X, sigma_Y]\n",
    "\n",
    "            p_s_c = get_likelihood([currentPoints[0], currentPoints[1]], mu, sigma)\n",
    "\n",
    "            # Step b --- Multiply the current p(s_i|c_i) to p(s_1, s_2, ..., s_n|W)\n",
    "            p_s_w *= p_s_c\n",
    "            #print(\"current Psw for letter\",letter,\":\", p_s_w)\n",
    "        \n",
    "        # Step c --- Calculate p(w|s_1, s_2, ... s_n) from p(s_1, s_2, ..., s_n|w) and p(w). Append the result to list\n",
    "        p_w_s.append([word,p_w * p_s_w])\n",
    "        #print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    # Step d ---- Choose word by the maximum of p(w|s_1, s_2, ..., s_n)\n",
    "    decoded_word = [0,0]\n",
    "    for i in p_w_s:\n",
    "        if(i[1] > decoded_word[1]):\n",
    "            decoded_word = i\n",
    "    print(\"decoded word:\",decoded_word)\n",
    "    return decoded_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WrRbMoZRCZ_u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded word: ['of', 0.029047445221393003]\n",
      "decoded word: ['at', 0.01184092565970868]\n",
      "decoded word: ['first', 0.011764732946123232]\n",
      "decoded word: ['you', 0.005683873533510627]\n",
      "decoded word: ['fail', 0.0001957528278073561]\n",
      "decoded word: ['we', 0.006103504863621498]\n",
      "decoded word: ['run', 0.00010371591245248646]\n",
      "decoded word: ['the', 0.14541859444022515]\n",
      "decoded word: ['risk', 0.000581184300940589]\n",
      "decoded word: ['of', 0.026721395787936676]\n",
      "decoded word: ['failure', 0.00344753225195269]\n",
      "decoded word: ['watch', 0.0008550965587149302]\n",
      "decoded word: ['out', 0.005136186899907617]\n",
      "decoded word: ['for', 0.03774233952582118]\n",
      "decoded word: ['low', 0.0005126656465539986]\n",
      "decoded word: ['objects', 0.0005399040945201277]\n",
      "decoded word: ['please', 0.010919431812241465]\n",
      "decoded word: ['provide', 0.003602095194317145]\n",
      "decoded word: ['your', 0.016457413356985147]\n",
      "decoded word: ['date', 0.006943528233360514]\n",
      "decoded word: ['circumference', 2.9634741919390577e-18]\n",
      "decoded word: ['are', 0.019438314973602315]\n",
      "decoded word: ['poor', 0.000113687260310495]\n",
      "decoded word: ['a', 0.033016759153052216]\n",
      "decoded word: ['problem', 0.0005025348201277375]\n",
      "decoded word: ['with', 0.003100031587938991]\n",
      "decoded word: ['the', 0.11464106251680332]\n",
      "decoded word: ['engine', 0.00011228917703878723]\n",
      "decoded word: ['my', 0.002651285453282915]\n",
      "decoded word: ['favorite', 0.002215241795922224]\n",
      "decoded word: ['subject', 0.006366754245342761]\n",
      "decoded word: ['elephants', 2.8991224775975987e-05]\n",
      "decoded word: ['are', 0.020947853036955576]\n",
      "decoded word: ['large', 0.0006398020417809627]\n",
      "decoded word: ['my', 0.004848749373923968]\n",
      "decoded word: ['favorite', 0.006678246899178704]\n",
      "decoded word: ['place', 0.0009981131363562296]\n",
      "decoded word: ['to', 0.0731217796332851]\n",
      "decoded word: ['visit', 0.0003204064892832613]\n",
      "decoded word: ['can', 0.0031687890778060055]\n",
      "decoded word: ['i', 0.010224267752505994]\n",
      "decoded word: ['skate', 8.636125987759454e-05]\n",
      "decoded word: ['with', 0.006929064312652113]\n",
      "decoded word: ['sister', 1.908960181416887e-05]\n",
      "decoded word: ['neither', 7.71740243332199e-05]\n",
      "decoded word: ['a', 0.03422448500260877]\n",
      "decoded word: ['borrower', 8.875099088977313e-06]\n",
      "decoded word: ['a', 0.03527402613074557]\n",
      "decoded word: ['question', 4.588117866339435e-05]\n",
      "decoded word: ['to', 0.004700511949245195]\n",
      "decoded word: ['answer', 0.0003004441056814313]\n",
      "decoded word: ['three', 0.0013656613400695665]\n",
      "decoded word: ['two', 0.0011481317265256987]\n",
      "decoded word: ['one', 0.002442215484353418]\n",
      "decoded word: ['zero', 0.00018481636777510898]\n",
      "decoded word: ['one', 0.0014855144014471074]\n",
      "decoded word: ['heck', 3.5091522296913726e-05]\n",
      "decoded word: ['of', 0.035899268122455315]\n",
      "decoded word: ['a', 0.025822763133551366]\n",
      "decoded word: ['question', 0.0018085645648388867]\n",
      "decoded word: ['the', 0.3181131410447625]\n",
      "decoded word: ['world', 0.003051634553985053]\n",
      "decoded word: ['is', 0.0030259272738797052]\n",
      "decoded word: ['a', 0.03134305306480006]\n",
      "decoded word: ['stage', 0.0003116195225873245]\n",
      "decoded word: ['prayer', 0.00023208640024065887]\n",
      "decoded word: ['on', 0.011620437895407346]\n",
      "decoded word: ['schools', 0.00019563436914255133]\n",
      "decoded word: ['offends', 1.426594386151094e-07]\n",
      "decoded word: ['you', 0.012695701011523234]\n",
      "decoded word: ['must', 0.0042164642295051255]\n",
      "decoded word: ['be', 0.011025306217590267]\n",
      "decoded word: ['getting', 0.00019693909227193443]\n",
      "decoded word: ['old', 0.0005038631590537003]\n",
      "decoded word: ['he', 0.0034934529447409606]\n",
      "decoded word: ['is', 0.02837534179046424]\n",
      "decoded word: ['must', 0.00042845226671602867]\n",
      "decoded word: ['like', 0.005276346426633651]\n",
      "decoded word: ['everyone', 0.00018993553927681026]\n",
      "decoded word: ['a', 0.031876231319069796]\n",
      "decoded word: ['great', 0.009246487942610251]\n",
      "decoded word: ['disturbance', 0.0001562935137684399]\n",
      "decoded word: ['love', 0.0021098567686322883]\n",
      "decoded word: ['means', 0.001751112054617436]\n",
      "decoded word: ['many', 0.0019372307432757587]\n",
      "decoded word: ['things', 0.0001839587102761814]\n",
      "decoded word: ['you', 0.013203806044280656]\n",
      "decoded word: ['are', 0.01869991475955296]\n",
      "decoded word: ['not', 0.008694586407844642]\n",
      "decoded word: ['a', 0.014536311668787239]\n",
      "decoded word: ['jedi', 3.43689256554243e-05]\n",
      "decoded word: ['yet', 0.00019207149431890708]\n",
      "decoded word: ['are', 0.021933810613930065]\n",
      "decoded word: ['you', 0.003321136046326385]\n",
      "decoded word: ['talking', 0.0006371074793369141]\n",
      "decoded word: ['to', 0.012225460840394718]\n",
      "decoded word: ['me', 0.0006091753320495194]\n",
      "decoded word: ['the', 0.4689472220039409]\n",
      "decoded word: ['force', 0.00021082661361281738]\n",
      "decoded word: ['is', 0.0034100841147111714]\n",
      "decoded word: ['with', 0.012861575177139399]\n",
      "decoded word: ['you', 0.000729072341613524]\n",
      "decoded word: ['an', 0.009306661381531212]\n",
      "decoded word: ['offer', 0.002395577946475391]\n",
      "decoded word: ['you', 0.004715149101063945]\n",
      "decoded word: ['cannot', 2.5389250535563282e-08]\n",
      "decoded word: ['refuse', 0.00021586858222969867]\n",
      "decoded word: ['play', 0.0003070414447139526]\n",
      "decoded word: ['it', 0.0019955829710124992]\n",
      "decoded word: ['again', 0.001992684252974435]\n",
      "decoded word: ['sam', 5.066205329527817e-05]\n",
      "decoded word: ['beware', 0.0004343723984273435]\n",
      "decoded word: ['the', 0.055021667971957275]\n",
      "decoded word: ['idea', 0.00013550164139162948]\n",
      "decoded word: ['of', 0.10871146457522964]\n",
      "decoded word: ['march', 0.0012447621061950508]\n",
      "decoded word: ['do', 0.0019765532597405375]\n",
      "decoded word: ['not', 0.00048288857048465783]\n",
      "decoded word: ['day', 0.003765835197792322]\n",
      "decoded word: ['anything', 8.993201474994979e-05]\n",
      "decoded word: ['double', 6.379399163875738e-06]\n",
      "decoded word: ['trouble', 0.00012286971938018588]\n",
      "decoded word: ['the', 0.03484000801171283]\n",
      "decoded word: ['power', 0.0002818703645813029]\n",
      "decoded word: ['of', 0.009027309180466687]\n",
      "decoded word: ['denial', 2.788544774966266e-06]\n",
      "decoded word: ['i', 0.009119253266177758]\n",
      "decoded word: ['agree', 0.0006731705967967605]\n",
      "decoded word: ['with', 0.005640272581289478]\n",
      "decoded word: ['you', 0.0006414871783011426]\n",
      "decoded word: ['space', 0.0018647101736583265]\n",
      "decoded word: ['is', 0.021289711840198098]\n",
      "decoded word: ['a', 0.032247171672753934]\n",
      "decoded word: ['high', 0.0005036696158417139]\n",
      "decoded word: ['priority', 0.00016080523604704322]\n",
      "decoded word: ['do', 0.0031486297229320914]\n",
      "decoded word: ['not', 0.003365442979363212]\n",
      "decoded word: ['squander', 3.031041806401825e-06]\n",
      "decoded word: ['your', 0.002477793659224224]\n",
      "decoded word: ['home', 0.0016975560058141996]\n",
      "decoded word: ['six', 0.00020091595039210607]\n",
      "decoded word: ['you', 0.0019284363037088317]\n",
      "decoded word: ['have', 0.0003096976608202481]\n",
      "decoded word: ['a', 0.00880278419150483]\n",
      "decoded word: ['good', 0.0002883857806192372]\n",
      "decoded word: ['time', 0.0014225934963136844]\n",
      "decoded word: ['you', 0.009188536699803573]\n",
      "decoded word: ['are', 0.025296729998913373]\n",
      "decoded word: ['wonderful', 0.0006484123113353835]\n",
      "decoded word: ['the', 0.19573064689477646]\n",
      "decoded word: ['dreamers', 4.166414527890017e-05]\n",
      "decoded word: ['of', 0.04548581842243836]\n",
      "decoded word: ['dreams', 0.0006456576578168466]\n"
     ]
    }
   ],
   "source": [
    "decoded_success_count = 0\n",
    "literal_success_count = 0\n",
    "decoded_words = []\n",
    "literal_strings = []\n",
    "correct_words = []\n",
    "for word in words:\n",
    "    touchpoints = words[word]\n",
    "    \"\"\"\n",
    "    Use above methods to compute the correct word, decoded word, and the literal string for each touch point collection\n",
    "          Append results to the corresponding list\n",
    "          Update the decoded words/literal strings success count. \n",
    "              --- If the decoded word/literal string is the same as correct word, increase 1 to decoded words/literal strings success count\n",
    "    \"\"\"\n",
    "    decoded_words.append(unigram_lm_decoder(touchpoints))\n",
    "    literal_strings.append(get_literal_string(touchpoints))\n",
    "\n",
    "    correct_word = ''\n",
    "    for points in touchpoints:\n",
    "        correct_word+= points[2]\n",
    "\n",
    "    correct_words.append(correct_word)\n",
    "\n",
    "# calculate the success rate for both the decoded words and the literal strings using the docoded word/literal string success count\n",
    "for i in range(len(decoded_words)):\n",
    "    if(correct_words[i] == decoded_words[i][0]):\n",
    "        decoded_success_count+=1\n",
    "    if(correct_words[i] == literal_strings[i]):\n",
    "        literal_success_count +=1\n",
    "# Write to results.txt\n",
    "with open(\"results.txt\", 'w') as output:\n",
    "    # The first line: success_rate(decoded_words), success_rate(literal_strings)\n",
    "    tmp = str(decoded_success_count/len(correct_words)) + \",\" + str(literal_success_count/len(correct_words)) + \"\\n\"\n",
    "    output.write(tmp)\n",
    "    for i in range(len(decoded_words)):\n",
    "        tmp = str(correct_words[i]) + \", \"+ str(decoded_words[i][0])+ \", \" + str(literal_strings[i])+ \"\\n\"\n",
    "        output.write(tmp)\n",
    "        # Each line after: correct_word, decoded_word, literal_string\n",
    "    output.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python392jvsc74a57bd0b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}