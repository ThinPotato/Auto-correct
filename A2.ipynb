{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1615908962928,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "keicKV6X8Y0Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zk2tzdcynYn"
   },
   "source": [
    "# **Read Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lpfFShdy3e5J"
   },
   "outputs": [],
   "source": [
    "# Read user data\n",
    "lastWord = \"\"\n",
    "words = defaultdict(dict)\n",
    "with open('Data/data.txt', 'r') as input:\n",
    "    for line in input:\n",
    "        touchpoints = [0,0, '']\n",
    "        line.strip\n",
    "        if line.startswith(\"===\"):\n",
    "            words[str(line)[3:len(str(line))-4]] = []\n",
    "            lastWord = str(line)[3:len(str(line))-4]\n",
    "        else:\n",
    "            tempPoints = str(line)[0:len(str(line))-2].split(\" \")\n",
    "            touchpoints[0] = float(tempPoints[1])\n",
    "            touchpoints[1] = float(tempPoints[2])\n",
    "            touchpoints[2] = tempPoints[0]\n",
    "            words[lastWord].append(touchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1615913307462,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "34cXvsWno6Yv",
    "outputId": "96c3f6f7-2867-4996-bd8e-0190d649e806"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>x_mm</th>\n      <th>y_mm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>4.025010</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>18.900047</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>12.950032</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d</td>\n      <td>9.975025</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>8.487521</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f</td>\n      <td>12.950032</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>g</td>\n      <td>15.925039</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>h</td>\n      <td>18.900047</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>i</td>\n      <td>23.362558</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>j</td>\n      <td>21.875053</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>k</td>\n      <td>24.850061</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>l</td>\n      <td>27.825070</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>m</td>\n      <td>24.850061</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>n</td>\n      <td>21.875053</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>o</td>\n      <td>26.337564</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>p</td>\n      <td>29.312572</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>q</td>\n      <td>2.537506</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r</td>\n      <td>11.462528</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>s</td>\n      <td>7.000017</td>\n      <td>9.625024</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>t</td>\n      <td>14.437536</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>u</td>\n      <td>20.387550</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>v</td>\n      <td>15.925039</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>w</td>\n      <td>5.512514</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>x</td>\n      <td>9.975025</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>y</td>\n      <td>17.412542</td>\n      <td>5.600014</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>z</td>\n      <td>7.000017</td>\n      <td>13.650034</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td></td>\n      <td>12.950032</td>\n      <td>17.675043</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   key       x_mm       y_mm\n0    a   4.025010   9.625024\n1    b  18.900047  13.650034\n2    c  12.950032  13.650034\n3    d   9.975025   9.625024\n4    e   8.487521   5.600014\n5    f  12.950032   9.625024\n6    g  15.925039   9.625024\n7    h  18.900047   9.625024\n8    i  23.362558   5.600014\n9    j  21.875053   9.625024\n10   k  24.850061   9.625024\n11   l  27.825070   9.625024\n12   m  24.850061  13.650034\n13   n  21.875053  13.650034\n14   o  26.337564   5.600014\n15   p  29.312572   5.600014\n16   q   2.537506   5.600014\n17   r  11.462528   5.600014\n18   s   7.000017   9.625024\n19   t  14.437536   5.600014\n20   u  20.387550   5.600014\n21   v  15.925039  13.650034\n22   w   5.512514   5.600014\n23   x   9.975025  13.650034\n24   y  17.412542   5.600014\n25   z   7.000017  13.650034\n26      12.950032  17.675043"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dictionary\n",
    "with open('Data/unigram.dict', 'rb') as unigramModelFile:\n",
    "    unigramModel = pickle.load(unigramModelFile)\n",
    "unigramModelFile.close()\n",
    "\n",
    "# Read keyboard data\n",
    "keyboard_raw = pd.read_csv(\"Data/keyboard.csv\")\n",
    "keyboard = keyboard_raw[['key', 'x_mm', 'y_mm']]\n",
    "keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuntaNwhyuJj"
   },
   "source": [
    "# **Unigram Language Model Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1615909214779,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "AaTGhNueN9hD"
   },
   "outputs": [],
   "source": [
    "# Keyboard size and dual Gaussian model parameters\n",
    "key_width = 3\n",
    "key_height = 4\n",
    "a = 2.403\n",
    "b = 0.017\n",
    "c = 2.295\n",
    "d = 0.016\n",
    "\n",
    "def get_likelihood(p, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the likelihood that a touch point p is from the 2D Gaussian distribution N(mu, sigma)\n",
    "    \"\"\"  \n",
    "    lik = a * math.exp(-(math.pow((p[0]-mu[0]),2)/(2*(a+b*math.pow(key_width,2)))+(math.pow(p[1]-mu[1],2)/(2*(c+d*math.pow(key_height,2))))))\n",
    "    return lik          \n",
    "\n",
    "def is_letter(p, letter):\n",
    "    \"\"\"\n",
    "    Determine if touch point p is located inside the boundary of the key: letter\n",
    "    \"\"\"\n",
    "    tmp = keyboard.loc[keyboard['key'] == letter]\n",
    "    x_mm = tmp.iloc[0]['x_mm']\n",
    "    y_mm = tmp.iloc[0]['y_mm']\n",
    "    if p[0] < (x_mm + key_width) and p[0] > x_mm and p[1] < (y_mm + key_height) and p[1] > y_mm:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def get_literal_string(touchpoints):\n",
    "    \"\"\" \n",
    "    Compute the literal string using is_letter(p, letter) method for a collection of touch points that represents a word. \n",
    "          If a touch point does not fall inside any key boundary, use '?' to represent the corresponding character.\n",
    "    \"\"\"\n",
    "    literal_string = \"\"\n",
    "    tmp = keyboard['key']\n",
    "    for touchpoint in touchpoints:\n",
    "        found = False\n",
    "        for i in range(25):\n",
    "            letter = tmp.values[i]\n",
    "            if is_letter(touchpoint, letter):\n",
    "                literal_string += letter\n",
    "                found = True\n",
    "        if found == False:\n",
    "            literal_string+= \"?\"\n",
    "    return literal_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1615909358093,
     "user": {
      "displayName": "Yan Ma",
      "photoUrl": "",
      "userId": "13133035010264584735"
     },
     "user_tz": 240
    },
    "id": "_op29UXGRmc0"
   },
   "outputs": [],
   "source": [
    "def unigram_lm_decoder(touchpoints):\n",
    "    \"\"\"\n",
    "    A language decoder that uses the dual Gaussian touch point spatial disrtibution model and a unigram language model.\n",
    "    Input: a list/collection of touch points that represents a certain word\n",
    "    Output: the decoded word for the input\n",
    "    \n",
    "    Step a --- Get all possible words and their corresponding probabilities from the dictionary. \n",
    "          Use the length of the correct word to filter possible words\n",
    "          You may also use the first and/or the last touchpoint to further narrow down possible words\n",
    "    \"\"\"\n",
    "    possible_words = []\n",
    "    length = len(touchpoints)\n",
    "    firstTP = touchpoints[0]\n",
    "    lastTP = touchpoints[len(touchpoints)-1]\n",
    "    possible_words = dict(filter(lambda x: len(str(x[0])) == length, unigramModel.items()))\n",
    "    #possible_words = dict(filter(lambda x: is_letter(firstTP, x[0][:1]), unigramModel.items()))\n",
    "    \n",
    "    # Calculate p(w|s_1, s_2, ... s_n) ~ p(s_1, s_2, ..., s_n|w)*p(w) = \\Pi(p(s_i|c_i))p(w) for each possible word\n",
    "    p_w_s = []                  # Holds p(w|s_1, s_2, ..., s_n) for all possible words\n",
    "    for item in possible_words:\n",
    "        word = item                  # The current possible word\n",
    "        p_w =  possible_words[item]  # Probability of the current possible word in the unigram language model\n",
    "        p_s_w = 1                 # Holds p(s_1, s_2, ..., s_n|w) for the current possible word\n",
    "\n",
    "        for j, letter in enumerate(list(word)):\n",
    "            currentPoints = touchpoints[j]\n",
    "            # Step b --- Apply the spatial model to get p(s_i|c_i)\n",
    "            tmp = keyboard.loc[keyboard['key'] == letter]\n",
    "            x_mm = tmp.iloc[0]['x_mm']\n",
    "            y_mm = tmp.iloc[0]['y_mm']\n",
    "            mu = [x_mm + (0.5*key_width), y_mm + (0.5*key_height)] # mu = center of key ci\n",
    "\n",
    "            sigma =[a+b*math.pow(key_width,2),c+d*math.pow(key_height,2)] # [sigma_X, sigma_Y]\n",
    "\n",
    "            p_s_c = get_likelihood([currentPoints[0], currentPoints[1]], mu, sigma)\n",
    "\n",
    "            # Step b --- Multiply the current p(s_i|c_i) to p(s_1, s_2, ..., s_n|W)\n",
    "            p_s_w *= p_s_c\n",
    "            #print(\"current Psw for letter\",letter,\":\", p_s_w)\n",
    "        \n",
    "        # Step c --- Calculate p(w|s_1, s_2, ... s_n) from p(s_1, s_2, ..., s_n|w) and p(w). Append the result to list\n",
    "        p_w_s.append([word,p_w * p_s_w])\n",
    "        #print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    # Step d ---- Choose word by the maximum of p(w|s_1, s_2, ..., s_n)\n",
    "    decoded_word = [0,0]\n",
    "    for i in p_w_s:\n",
    "        if(i[1] > decoded_word[1]):\n",
    "            decoded_word = i\n",
    "    print(\"decoded word:\",decoded_word)\n",
    "    return decoded_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WrRbMoZRCZ_u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded word: ['a', 0.014206173329411445]\n",
      "decoded word: ['problem', 0.000349393826075834]\n",
      "decoded word: ['with', 0.005784631131583281]\n",
      "decoded word: ['the', 0.054764326296966405]\n",
      "decoded word: ['engine', 0.000257729463224217]\n",
      "decoded word: ['please', 0.002945486717661759]\n",
      "decoded word: ['provide', 0.00016935573000656184]\n",
      "decoded word: ['your', 0.003577660256003527]\n",
      "decoded word: ['date', 0.005067378771462644]\n",
      "decoded word: ['we', 0.00490150821021408]\n",
      "decoded word: ['run', 0.00021023232455039467]\n",
      "decoded word: ['the', 0.05255184998822622]\n",
      "decoded word: ['risk', 9.58565929246257e-05]\n",
      "decoded word: ['of', 0.014930354593316276]\n",
      "decoded word: ['failure', 0.00020223267657934883]\n",
      "decoded word: ['my', 0.0024831199889199466]\n",
      "decoded word: ['favorite', 0.00022005881555797779]\n",
      "decoded word: ['place', 0.000537721797096096]\n",
      "decoded word: ['to', 0.015444652579832812]\n",
      "decoded word: ['visit', 0.0015833389170577716]\n",
      "decoded word: ['circumstances', 0.00012797950738618208]\n",
      "decoded word: ['are', 0.024444043992449704]\n",
      "decoded word: ['poor', 0.00025891087383345823]\n",
      "decoded word: ['elephants', 1.547045231580606e-06]\n",
      "decoded word: ['are', 0.005793848827109149]\n",
      "decoded word: ['large', 0.0002469119737862058]\n",
      "decoded word: ['watch', 0.000706339412303876]\n",
      "decoded word: ['out', 0.006340228696089039]\n"
     ]
    }
   ],
   "source": [
    "decoded_success_count = 0\n",
    "literal_success_count = 0\n",
    "decoded_words = []\n",
    "literal_strings = []\n",
    "correct_words = []\n",
    "for word in words:\n",
    "    touchpoints = words[word]\n",
    "    \"\"\"\n",
    "    Use above methods to compute the correct word, decoded word, and the literal string for each touch point collection\n",
    "          Append results to the corresponding list\n",
    "          Update the decoded words/literal strings success count. \n",
    "              --- If the decoded word/literal string is the same as correct word, increase 1 to decoded words/literal strings success count\n",
    "    \"\"\"\n",
    "    decoded_words.append(unigram_lm_decoder(touchpoints))\n",
    "    literal_strings.append(get_literal_string(touchpoints))\n",
    "\n",
    "    correct_word = ''\n",
    "    for points in touchpoints:\n",
    "        correct_word+= points[2]\n",
    "\n",
    "    correct_words.append(correct_word)\n",
    "\n",
    "# calculate the success rate for both the decoded words and the literal strings using the docoded word/literal string success count\n",
    "for i in range(len(decoded_words)):\n",
    "    if(correct_words[i] == decoded_words[i][0]):\n",
    "        decoded_success_count+=1\n",
    "    if(correct_words[i] == literal_strings[i]):\n",
    "        literal_success_count +=1\n",
    "# Write to results.txt\n",
    "with open(\"results.txt\", 'w') as output:\n",
    "    # The first line: success_rate(decoded_words), success_rate(literal_strings)\n",
    "    tmp = str(decoded_success_count/len(correct_words)) + \",\" + str(literal_success_count/len(correct_words)) + \"\\n\"\n",
    "    output.write(tmp)\n",
    "    for i in range(len(decoded_words)):\n",
    "        tmp = str(correct_words[i]) + \", \"+ str(decoded_words[i][0])+ \", \" + str(literal_strings[i])+ \"\\n\"\n",
    "        output.write(tmp)\n",
    "        # Each line after: correct_word, decoded_word, literal_string\n",
    "    output.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python392jvsc74a57bd0b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}